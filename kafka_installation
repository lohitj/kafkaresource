1. Preparing the VMs for Kafka
2. Configuring the Zookeeper
3. Configuring Kafka Brokers
4. Testing Kafka Installation

-----------------------------------

1.Once creating the 4 vm's (3 for broker and 1 for zookeeper) with RHEL-7 base OS and 10 GB disks.in public subnet.
2. The first thing that we need on these four VMs is the JDK 1.8. I will install OpenJDK for the sake of simplicity. 
# sudo yum -y install java-1.8.0-openjdk   
------------------------------------------------------------------------------------------------------------------------
3. Now we want to download Apache Kafka binaries. I will need the wget tool to download anything on the VMs. So, let’s install wget. Execute the yum command. 
# sudo yum -y install wget  
-----------------------------------------------------------------------------------------------------------------
4. Now you are ready to download Apache Kafka binaries. 
Copy one of the mirror URL and download Kafka binaries using wget command.
get link from mirror site - https://www.apache.org/dyn/closer.cgi?path=/kafka/2.0.0/kafka_2.12-2.0.0.tgz
# wget http://www-eu.apache.org/dist/kafka/2.3.0/kafka_2.12-2.3.0.tgz

------------------------------------------------------------------------------------------------------------------
5. Let’s uncompress the binaries. You can use the tar command.
# tar -xzf kafka_2.12-2.0.0.tgz    


The bin directory and the config directory. 
The bin folder holds all executables such as various Kafka and Zookeeper tools. 
The config directory holds two main configuration files.
1. zookeeper.properties
2. server.properties
We define all Zookeeper configurations in the zookeeper.properties file. 
And all Kafka broker configurations are defined in the server.properties file. 
------------------------------------------------------------------------------------------------------------------------

6. Add the bin directory in our PATH environment variable. 

# PATH=$PATH:$HOME/kafka_2.12-2.3.0/bin  
# source ~/.bash_profile
------------------------------------------------------------------------------------------------------------------------  

7. Configure and start the Zookeeper server.
# vi $HOME/kafka_2.12-2.3.0/config/zookeeper.properties.
 dataDir=/home/ec2-user/zookeeper_data
# mkdir $HOME/zookeeper_data
$HOME/kafka_2.12-2.3.0/bin/zookeeper-server-start.sh /home/ec2-user/kafka_2.12-2.3.0/config/zookeeper.properties

8. Open you /etc/rc.d/rc.local file and place the start command at the bottom of the file. Make sure to specify the full path.
To enable zookeeper accross reboot.
# sudo vi /etc/rc.d/rc.local
Add below line and save and exit.
/home/ec2-user/kafka_2.12-2.3.0/bin/zookeeper-server-start.sh /home/ec2-user/kafka_2.12-2.3.0/config/zookeeper.properties> /dev/null 2>&1 &

Edit for execute permission on file.
# sudo chmod +x /etc/rc.d/rc.local
# sudo systemctl enable rc-local
# sudo systemctl start rc-local

We are done. Do you want to test your Zookeeper server? For testing use below command. Currently no node found to zookeeper.

[ec2-user@server-4 ~]$ kafka_2.12-2.3.0/bin/zookeeper-shell.sh 13.58.143.103:2181 ls /brokers/ids
Connecting to 13.58.143.103:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
Node does not exist: /brokers/ids
---------------------------------------------------------------------------------------------------------------------------------------------------------------------

9. Configuring Kafka Brokers

* Create directory for zookeeper data on all nodes
# mkdir /home/ec2-user/kafka_data

*broker.id=0  then add as 1 and 2 for other 2 kafka brokers.
*broker.rack=RACK1  (for 1& 2nd it is same but for 3rd broker it is RACK2)
*log.dirs location=/home/ec2-user/kafka_data --> base directory where kafka broker stores the partition replica.
*offset.topic.num.partitions=3 --> kafka internally creates a topic to store offsets, this config controls the number of partitions for offset topic.
default number is 50.doesn't required for dev so will take it as 3.
zookeeper.connect - It specifies the hostname/IP and port number of zookeeper on each node.
-------------------------------------------------------------------------------------------------------------------------------------------

10. Once done with all configuration, start the kafka broker on all nodes.

# /home/ec2-user/kafka_2.12-2.3.0/bin/kafka-server-start.sh /home/ec2-user/kafka_2.12-2.3.0/config/server.properties

Make below entry in /etc/rc.d/rc.local on all broker nodes to get the broker started automatically accross reboot. 

/home/ec2-user/kafka_2.12-2.3.0/bin/kafka-server-start.sh /home/ec2-user/kafka_2.12-2.3.0/config/server.properties> /dev/null 2>&1 & 

Make the file executable.
# sudo chmod +x /etc/rc.d/rc.local

Add your rc-local service to systemctl.
# sudo systemctl enable rc-local

Start your rc-local service.
# sudo systemctl start rc-local

==============================================================================================================================================

11. Testing Kafka Installation
Execute Zookeeper shell and check the list of active broker IDs.
# [ec2-user@server-4 ~]$ zookeeper-shell.sh 172.31.45.109:2181 ls /brokers/ids
Connecting to 172.31.45.109:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[0, 1, 2]
[ec2-user@server-4 ~]$
=============================================================================================================================================

Login / ssh to one of node and create the topic to test.
# kafka-topics.sh --create --zookeeper <IP_address>:2181 --replication-factor 3 --partitions 3 --topic test
kafka-topics.sh --create --zookeeper 172.31.45.109:2181 --replication-factor 3 --partitions 3 --topic test

List the topics.
# kafka-topics.sh --list --zookeeper <IP_address>:2181

To send the topics from one of broker node.
# kafka-console-producer.sh --broker-list <broker_IP_Addr>:9092 --topic test
kafka-console-producer.sh --broker-list 172.31.16.70:9092 --topic test

Type your message..
>Hello World..
-----------------------------------------------------------------------------------------------------------------------------------------------

To test on Consumer on another broker node.
# kafka-console-consumer.sh --bootstrap-server <broker_IP>:9092 --topic test --from-beginning
kafka-console-consumer.sh --bootstrap-server 172.31.18.14:9092 --topic test --from-beginning
--------------------------------------------------------------------------

======================================================================================================================================================


Ports
By default the Confluent Platform components use these ports to communicate. These ports must be open.

Component	Port
Kafkabrokers(plaintext)	9092
ConfluentControlCenter	9021
KafkaConnectRESTAPI	8083
KSQLServerRESTAPI	8088
RESTProxy	8082
SchemaRegistryRESTAPI	8081
ZooKeeper	2181
Range of ports - 8081 - 8083

